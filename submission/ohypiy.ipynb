{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "import catboost\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import f1_score\n",
    "import joblib\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './submission/models/model.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\hackaton\\HSE_Sber_Hack-2023\\submission\\ohypiy.ipynb Cell 2\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/hackaton/HSE_Sber_Hack-2023/submission/ohypiy.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m PATH_DATA \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m./data\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/hackaton/HSE_Sber_Hack-2023/submission/ohypiy.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m MODEL_PATH \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m./submission/models/\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/hackaton/HSE_Sber_Hack-2023/submission/ohypiy.ipynb#W1sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m clf \u001b[39m=\u001b[39m joblib\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(MODEL_PATH, \u001b[39m\"\u001b[39;49m\u001b[39mmodel.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n",
      "File \u001b[1;32md:\\code\\python\\Lib\\site-packages\\joblib\\numpy_pickle.py:650\u001b[0m, in \u001b[0;36mload\u001b[1;34m(filename, mmap_mode)\u001b[0m\n\u001b[0;32m    648\u001b[0m         obj \u001b[39m=\u001b[39m _unpickle(fobj)\n\u001b[0;32m    649\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m    651\u001b[0m         \u001b[39mwith\u001b[39;00m _read_fileobject(f, filename, mmap_mode) \u001b[39mas\u001b[39;00m fobj:\n\u001b[0;32m    652\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(fobj, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    653\u001b[0m                 \u001b[39m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[0;32m    654\u001b[0m                 \u001b[39m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[0;32m    655\u001b[0m                 \u001b[39m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './submission/models/model.pkl'"
     ]
    }
   ],
   "source": [
    "PATH_DATA = './data'\n",
    "MODEL_PATH = \"./submission/models/\"\n",
    "\n",
    "clf = joblib.load(os.path.join(MODEL_PATH, \"model.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_mcc_codes = pd.read_csv(os.path.join(PATH_DATA, 'mcc_codes.csv'), sep=';', index_col='mcc_code')\n",
    "tr_types = pd.read_csv(os.path.join(PATH_DATA, 'trans_types.csv'), sep=';', index_col='trans_type')\n",
    "transactions = pd.read_csv(os.path.join(PATH_DATA, 'transactions.csv'), index_col='client_id')\n",
    "gender_test = pd.read_csv(os.path.join(PATH_DATA, 'test.csv'), index_col='client_id')\n",
    "transactions_test = transactions.join(gender_test, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditions_day(x):\n",
    "    if x == 4:\n",
    "        return 'friday'\n",
    "    elif (x == 5 or x == 6):\n",
    "        return 'weekend'\n",
    "    else:\n",
    "        return 'weekday'\n",
    "conds_d = np.vectorize(conditions_day)\n",
    "\n",
    "def conditions_hour(x):\n",
    "    if (x >= 6) and (x < 12):\n",
    "        return 'morning'\n",
    "    elif (x >= 12) and (x < 18):\n",
    "        return 'daytime'\n",
    "    elif (x >= 18) and (x <= 23):\n",
    "        return 'evening'\n",
    "    else:\n",
    "        return 'night'\n",
    "conds_h = np.vectorize(conditions_hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in transactions_test.iterrows():\n",
    "    transactions_test.at[idx, 'day_month'] = int(row['trans_time'].split()[0]) % 30\n",
    "    transactions_test.at[idx, 'month'] = (int(row['trans_time'].split()[0]) // 30) % 12\n",
    "    transactions_test.at[idx, 'day'] = int(row['trans_time'].split()[0]) % 7\n",
    "    transactions_test.at[idx, 'hour'] = int(re.search(' \\d*', row['trans_time']).group(0))\n",
    "    type_day = conds_d(transactions_test.at[idx, 'day'])\n",
    "    transactions_test.at[idx, 'type_day'] = type_day\n",
    "    part_day = conds_h(transactions_test.at[idx, 'hour'])\n",
    "    transactions_test.at[idx, 'part_day'] = part_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm_notebook.pandas(desc=\"Progress:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def features_advanced(x): \n",
    "    features = []\n",
    "    features.append(pd.Series(x['day_month'].value_counts(normalize=True).add_prefix('day_month_')))\n",
    "    features.append(pd.Series(x['month'].value_counts(normalize=True).add_prefix('month_')))\n",
    "    features.append(pd.Series(x['day'].value_counts(normalize=True).add_prefix('day_')))\n",
    "    features.append(pd.Series(x['hour'].value_counts(normalize=True).add_prefix('hour_')))\n",
    "    features.append(pd.Series(x['type_day'].value_counts(normalize=True).add_prefix('type_day_')))\n",
    "    features.append(pd.Series(x['part_day'].value_counts(normalize=True).add_prefix('part_day_')))\n",
    "    \n",
    "    features.append(pd.Series(x[x['amount']>0]['amount'].agg(['min', 'max', 'mean', 'median', 'std', 'count', 'sum'])\\\n",
    "                                                        .add_prefix('positive_transactions_')))\n",
    "    features.append(pd.Series(x[x['amount']<0]['amount'].agg(['min', 'max', 'mean', 'median', 'std', 'count', 'sum'])\\\n",
    "                                                        .add_prefix('negative_transactions_')))\n",
    "\n",
    "    features.append(pd.Series(x['mcc_code'].value_counts(normalize=True).add_prefix('mcc_')))\n",
    "    features.append(pd.Series(x['trans_type'].value_counts(normalize=True).add_prefix('tr_')))\n",
    "    features.append(pd.Series(x[['day_month', 'part_day']].value_counts(normalize=True).add_prefix('dm_pd_')))\n",
    "    \n",
    "    return pd.concat(features)\n",
    "\n",
    "data_test = transactions_test.groupby(transactions_test.index)\\\n",
    "                            .progress_apply(features_advanced).unstack(-1)\n",
    "\n",
    "target = data_test.join(gender_test, how='inner')['gender']\n",
    "target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_pred = clf.predict(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "submission = pd.DataFrame(index=data_test.index)\n",
    "submission['probability'] = y_pred[:,1]\n",
    "submission.to_csv('result.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
